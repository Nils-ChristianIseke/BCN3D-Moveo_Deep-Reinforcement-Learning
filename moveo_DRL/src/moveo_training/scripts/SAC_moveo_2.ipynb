{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "import sys\n",
                "sys.executable\n",
                "import os\n",
                "os.getcwd()\n",
                "sys.path.append('devel/lib/python3/dist-packages/theconstruct_msgs/msg/')\n",
                "sys.path.append('/home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/src')\n",
                "sys.path.append('/home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/src/moveo_training/scripts')\n",
                "sys.path.append('/home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/devel/lib/python3/dist-packages/openai_ros/msg')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "import base64\n",
                "import imageio\n",
                "import IPython\n",
                "import matplotlib.pyplot as plt\n",
                "import os\n",
                "import reverb\n",
                "import tempfile\n",
                "import PIL.Image\n",
                "\n",
                "import tensorflow as tf\n",
                "import moveo_inverse_kinematic_2\n",
                "from tf_agents.environments import suite_gym\n",
                "from tf_agents.agents.ddpg import critic_network\n",
                "from tf_agents.agents.sac import sac_agent\n",
                "from tf_agents.agents.sac import tanh_normal_projection_network\n",
                "from tf_agents.environments import suite_pybullet\n",
                "from tf_agents.metrics import py_metrics\n",
                "from tf_agents.networks import actor_distribution_network\n",
                "from tf_agents.policies import greedy_policy\n",
                "from tf_agents.policies import py_tf_eager_policy\n",
                "from tf_agents.policies import random_py_policy\n",
                "from tf_agents.replay_buffers import reverb_replay_buffer\n",
                "from tf_agents.replay_buffers import reverb_utils\n",
                "from tf_agents.train import actor\n",
                "from tf_agents.train import learner\n",
                "from tf_agents.train import triggers\n",
                "from tf_agents.train.utils import spec_utils\n",
                "from tf_agents.train.utils import strategy_utils\n",
                "from tf_agents.train.utils import train_utils\n",
                "import rospy\n",
                "from gym.envs.registration import register\n",
                "import gym\n",
                "tempdir = tempfile.gettempdir()"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "2021-08-21 15:28:09.347929: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/devel/lib:/opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu\n",
                        "2021-08-21 15:28:09.347948: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Failed to import pyassimp, see https://github.com/ros-planning/moveit/issues/86 for more info\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "num_iterations = 5000 # @param {type:\"integer\"}\n",
                "\n",
                "initial_collect_steps = 10 # @param {type:\"integer\"}\n",
                "collect_steps_per_iteration = 10 # @param {type:\"integer\"}\n",
                "replay_buffer_capacity = 1000 # @param {type:\"integer\"}\n",
                "\n",
                "batch_size = 256 # @param {type:\"integer\"}\n",
                "\n",
                "critic_learning_rate = 3e-4 # @param {type:\"number\"}\n",
                "actor_learning_rate = 3e-4 # @param {type:\"number\"}\n",
                "alpha_learning_rate = 3e-4 # @param {type:\"number\"}\n",
                "target_update_tau = 0.005 # @param {type:\"number\"}\n",
                "target_update_period = 1 # @param {type:\"number\"}\n",
                "gamma = 0.99 # @param {type:\"number\"}\n",
                "reward_scale_factor = 1.0 # @param {type:\"number\"}\n",
                "\n",
                "actor_fc_layer_params = (256, 256)\n",
                "critic_joint_fc_layer_params = (256, 256)\n",
                "\n",
                "log_interval = 50# @param {type:\"integer\"}\n",
                "\n",
                "num_eval_episodes = 1 # @param {type:\"integer\"}\n",
                "eval_interval = 100 # @param {type:\"integer\"}\n",
                "\n",
                "policy_save_interval = 1000 # @param {type:\"integer\"}"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "# env_name = 'MoveoIK-v0'\n",
                "# if env_name in gym.envs.registry.env_specs:\n",
                "#     del gym.envs.registry.env_specs[env_name]\n",
                "\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "# env_name = 'MoveoIK-v0'\n",
                "# if env_name in gym.envs.registry.env_specs:\n",
                "#     del gym.envs.registry.env_specs[env_name]\n",
                "\n",
                "# register(\n",
                "#         id=env_name ,\n",
                "#         entry_point='moveo_inverse_kinematic_2:MoveoIKEnv',\n",
                "#         max_episode_steps=max_episode_steps,\n",
                "#     )"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "source": [
                "rospy.init_node(\"train_moveo_her\")\n",
                "env_name = 'MoveoIK-v0' # @param {type:\"string\"}\n",
                "env = suite_gym.load('MoveoIK-v0')"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "###### Setting Group Moveit with 30 seconds wait...\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "[ERROR] [1629552493.125899, 119026.192000]: NOT Initialising Simulation Physics Parameters\n",
                        "[WARN] [1629552493.141383, 119026.365000]: Start Init ControllersConnection\n",
                        "[WARN] [1629552493.142505, 119026.365000]: END Init ControllersConnection\n",
                        "/home/nils/.local/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
                        "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "source": [
                "env.reset()"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "[WARN] [1629552493.255195, 119027.678000]: setting new goalpoint\n"
                    ]
                },
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "TimeStep(\n",
                            "{'discount': array(1., dtype=float32),\n",
                            " 'observation': array([0.3, 0.3, 0.3], dtype=float32),\n",
                            " 'reward': array(0., dtype=float32),\n",
                            " 'step_type': array(0, dtype=int32)})"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 7
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "source": [
                "print('Observation Spec:')\n",
                "print(env.time_step_spec().observation)\n",
                "print('Action Spec:')\n",
                "print(env.action_spec())"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Observation Spec:\n",
                        "BoundedArraySpec(shape=(3,), dtype=dtype('float32'), name='observation', minimum=-1.0, maximum=1.0)\n",
                        "Action Spec:\n",
                        "BoundedArraySpec(shape=(5,), dtype=dtype('float32'), name='action', minimum=-3.140000104904175, maximum=3.140000104904175)\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "source": [
                "collect_env = suite_gym.load(env_name)\n",
                "eval_env = suite_gym.load(env_name)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "###### Setting Group Moveit with 30 seconds wait...\n",
                        "###### Setting Group Moveit with 30 seconds wait...\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "[ERROR] [1629552494.398277, 119038.351000]: NOT Initialising Simulation Physics Parameters\n",
                        "[WARN] [1629552494.417153, 119038.552000]: Start Init ControllersConnection\n",
                        "[WARN] [1629552494.418893, 119038.557000]: END Init ControllersConnection\n",
                        "[ERROR] [1629552494.556839, 119039.990000]: NOT Initialising Simulation Physics Parameters\n",
                        "[WARN] [1629552494.562116, 119040.029000]: Start Init ControllersConnection\n",
                        "[WARN] [1629552494.563241, 119040.034000]: END Init ControllersConnection\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "source": [
                "use_gpu = True\n",
                "strategy = strategy_utils.get_strategy(tpu=False, use_gpu=use_gpu)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
                        "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
                        "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "2021-08-21 15:28:14.612486: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
                        "2021-08-21 15:28:14.641347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
                        "2021-08-21 15:28:14.641631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
                        "pciBusID: 0000:01:00.0 name: GeForce GTX 970 computeCapability: 5.2\n",
                        "coreClock: 1.2155GHz coreCount: 13 deviceMemorySize: 3.94GiB deviceMemoryBandwidth: 208.91GiB/s\n",
                        "2021-08-21 15:28:14.641721: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/devel/lib:/opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu\n",
                        "2021-08-21 15:28:14.641796: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/devel/lib:/opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu\n",
                        "2021-08-21 15:28:14.641867: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/devel/lib:/opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu\n",
                        "2021-08-21 15:28:14.641928: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/devel/lib:/opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu\n",
                        "2021-08-21 15:28:14.641989: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/devel/lib:/opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu\n",
                        "2021-08-21 15:28:14.642049: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/devel/lib:/opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu\n",
                        "2021-08-21 15:28:14.642109: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/devel/lib:/opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu\n",
                        "2021-08-21 15:28:14.642179: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/devel/lib:/opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu\n",
                        "2021-08-21 15:28:14.642188: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
                        "Skipping registering GPU devices...\n",
                        "2021-08-21 15:28:14.643709: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
                        "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
                        "2021-08-21 15:28:14.643870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
                        "2021-08-21 15:28:14.643880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "source": [
                "observation_spec, action_spec, time_step_spec = (\n",
                "      spec_utils.get_tensor_specs(collect_env))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "source": [
                "with strategy.scope():\n",
                "  critic_net = critic_network.CriticNetwork(\n",
                "        (observation_spec, action_spec),\n",
                "        observation_fc_layer_params=None,\n",
                "        action_fc_layer_params=None,\n",
                "        joint_fc_layer_params=critic_joint_fc_layer_params,\n",
                "        kernel_initializer='glorot_uniform',\n",
                "        last_kernel_initializer='glorot_uniform')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "source": [
                "with strategy.scope():\n",
                "  actor_net = actor_distribution_network.ActorDistributionNetwork(\n",
                "      observation_spec,\n",
                "      action_spec,\n",
                "      fc_layer_params=actor_fc_layer_params,\n",
                "      continuous_projection_net=(\n",
                "          tanh_normal_projection_network.TanhNormalProjectionNetwork))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "source": [
                "with strategy.scope():\n",
                "  train_step = train_utils.create_train_step()\n",
                "\n",
                "  tf_agent = sac_agent.SacAgent(\n",
                "        time_step_spec,\n",
                "        action_spec,\n",
                "        actor_network=actor_net,\n",
                "        critic_network=critic_net,\n",
                "        actor_optimizer=tf.compat.v1.train.AdamOptimizer(\n",
                "            learning_rate=actor_learning_rate),\n",
                "        critic_optimizer=tf.compat.v1.train.AdamOptimizer(\n",
                "            learning_rate=critic_learning_rate),\n",
                "        alpha_optimizer=tf.compat.v1.train.AdamOptimizer(\n",
                "            learning_rate=alpha_learning_rate),\n",
                "        target_update_tau=target_update_tau,\n",
                "        target_update_period=target_update_period,\n",
                "        td_errors_loss_fn=tf.math.squared_difference,\n",
                "        gamma=gamma,\n",
                "        reward_scale_factor=reward_scale_factor,\n",
                "        train_step_counter=train_step)\n",
                "\n",
                "  tf_agent.initialize()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "source": [
                "rate_limiter=reverb.rate_limiters.SampleToInsertRatio(samples_per_insert=3.0, min_size_to_sample=3, error_buffer=3.0)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "source": [
                "table_name = 'uniform_table'\n",
                "table = reverb.Table(\n",
                "    table_name,\n",
                "    max_size=replay_buffer_capacity,\n",
                "    sampler=reverb.selectors.Uniform(),\n",
                "    remover=reverb.selectors.Fifo(),\n",
                "    rate_limiter=reverb.rate_limiters.MinSize(1))\n",
                "\n",
                "reverb_server = reverb.Server([table])"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "[reverb/cc/platform/tfrecord_checkpointer.cc:150]  Initializing TFRecordCheckpointer in /tmp/tmpam1sg2h2.\n",
                        "[reverb/cc/platform/tfrecord_checkpointer.cc:378] Loading latest checkpoint from /tmp/tmpam1sg2h2\n",
                        "[reverb/cc/platform/default/server.cc:54] Started replay server on port 16003\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "source": [
                "reverb_replay = reverb_replay_buffer.ReverbReplayBuffer(\n",
                "    tf_agent.collect_data_spec,\n",
                "    sequence_length=2,\n",
                "    table_name=table_name,\n",
                "    local_server=reverb_server)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "source": [
                "dataset = reverb_replay.as_dataset(\n",
                "      sample_batch_size=batch_size, num_steps=2).prefetch(50)\n",
                "experience_dataset_fn = lambda: dataset"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "source": [
                "tf_eval_policy = tf_agent.policy\n",
                "eval_policy = py_tf_eager_policy.PyTFEagerPolicy(\n",
                "  tf_eval_policy, use_tf_function=True)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "source": [
                "tf_collect_policy = tf_agent.collect_policy\n",
                "collect_policy = py_tf_eager_policy.PyTFEagerPolicy(\n",
                "  tf_collect_policy, use_tf_function=True)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "source": [
                "random_policy = random_py_policy.RandomPyPolicy(\n",
                "  collect_env.time_step_spec(), collect_env.action_spec())"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "source": [
                "rb_observer = reverb_utils.ReverbAddTrajectoryObserver(\n",
                "  reverb_replay.py_client,\n",
                "  table_name,\n",
                "  sequence_length=2,\n",
                "  stride_length=1)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "source": [
                "initial_collect_actor = actor.Actor(\n",
                "  collect_env,\n",
                "  random_policy,\n",
                "  train_step,\n",
                "  steps_per_run=initial_collect_steps,\n",
                "  observers=[rb_observer])\n",
                "initial_collect_actor.run()"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "[WARN] [1629552496.005642, 119055.471000]: setting new goalpoint\n",
                        "[WARN] [1629552497.052305, 119065.201000]: setting new goalpoint\n",
                        "[WARN] [1629552497.104814, 119065.540000]: setting new goalpoint\n",
                        "[WARN] [1629552497.774063, 119070.997000]: setting new goalpoint\n",
                        "[WARN] [1629552497.819433, 119071.633000]: setting new goalpoint\n",
                        "[WARN] [1629552498.114098, 119074.598000]: setting new goalpoint\n",
                        "[WARN] [1629552498.145597, 119074.911000]: setting new goalpoint\n",
                        "[WARN] [1629552499.211579, 119084.072000]: setting new goalpoint\n",
                        "[WARN] [1629552499.271044, 119084.687000]: setting new goalpoint\n",
                        "[WARN] [1629552500.138328, 119093.784000]: setting new goalpoint\n",
                        "[WARN] [1629552500.185431, 119094.298000]: setting new goalpoint\n",
                        "[WARN] [1629552500.510962, 119096.924000]: setting new goalpoint\n",
                        "[WARN] [1629552500.578707, 119097.690000]: setting new goalpoint\n",
                        "[WARN] [1629552500.868116, 119099.512000]: setting new goalpoint\n",
                        "[WARN] [1629552500.917426, 119100.027000]: setting new goalpoint\n",
                        "\u001b[33m[ WARN] [1629552501.291774278, 119102.624000000]: Fail: ABORTED: No motion plan found. No execution attempted.\u001b[0m\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "source": [
                "env_step_metric = py_metrics.EnvironmentSteps()\n",
                "collect_actor = actor.Actor(\n",
                "  collect_env,\n",
                "  collect_policy,\n",
                "  train_step,\n",
                "  steps_per_run=1,\n",
                "  metrics=actor.collect_metrics(10),\n",
                "  summary_dir=os.path.join(tempdir, learner.TRAIN_DIR),\n",
                "  observers=[rb_observer, env_step_metric])"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "[WARN] [1629552501.462912, 119103.920000]: setting new goalpoint\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "source": [
                "\n",
                "\n",
                "eval_actor = actor.Actor(\n",
                "  eval_env,\n",
                "  eval_policy,\n",
                "  train_step,\n",
                "  episodes_per_run=num_eval_episodes,\n",
                "  metrics=actor.eval_metrics(num_eval_episodes),\n",
                "  summary_dir=os.path.join(tempdir, 'eval'),\n",
                ")\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "[WARN] [1629552501.835462, 119106.001000]: setting new goalpoint\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "source": [
                "saved_model_dir = os.path.join(tempdir, learner.POLICY_SAVED_MODEL_DIR)\n",
                "\n",
                "# Triggers to save the agent's policy checkpoints.\n",
                "learning_triggers = [\n",
                "    triggers.PolicySavedModelTrigger(\n",
                "        saved_model_dir,\n",
                "        tf_agent,\n",
                "        train_step,\n",
                "        interval=policy_save_interval),\n",
                "    triggers.StepPerSecondLogTrigger(train_step, interval=1000),\n",
                "]\n",
                "agent_learner = learner.Learner(\n",
                "  tempdir,\n",
                "  train_step,\n",
                "  tf_agent,\n",
                "  experience_dataset_fn,\n",
                "  triggers=learning_triggers)\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "WARNING:tensorflow:From /home/nils/.local/lib/python3.8/site-packages/tensorflow_probability/python/distributions/distribution.py:298: calling MultivariateNormalDiag.__init__ (from tensorflow_probability.python.distributions.mvn_diag) with scale_identity_multiplier is deprecated and will be removed after 2020-01-01.\n",
                        "Instructions for updating:\n",
                        "`scale_identity_multiplier` is deprecated; please combine it with `scale_diag` directly instead.\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "2021-08-21 15:28:22.436466: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "WARNING:tensorflow:From /home/nils/.local/lib/python3.8/site-packages/tf_agents/train/learner.py:145: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
                        "Instructions for updating:\n",
                        "rename to distribute_datasets_from_function\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "2021-08-21 15:28:22.888214: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
                        "2021-08-21 15:28:22.910298: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3192610000 Hz\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "source": [
                "\n",
                "def get_eval_metrics():\n",
                "  print(\"Starte evaluierung\")\n",
                "  eval_actor.run()\n",
                "  results = {}\n",
                "  for metric in eval_actor.metrics:\n",
                "    results[metric.name] = metric.result()\n",
                "  print(\"Evaluierung beendete\")\n",
                "  return results\n",
                "\n",
                "metrics = get_eval_metrics()\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Starte evaluierung\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "[WARN] [1629552508.561286, 119167.866000]: setting new goalpoint\n",
                        "[WARN] [1629552508.629777, 119168.621000]: setting new goalpoint\n",
                        "[WARN] [1629552508.930845, 119171.550000]: setting new goalpoint\n",
                        "[WARN] [1629552509.013496, 119172.415000]: setting new goalpoint\n",
                        "[WARN] [1629552509.365599, 119175.326000]: setting new goalpoint\n",
                        "[WARN] [1629552509.415766, 119175.719000]: setting new goalpoint\n",
                        "[WARN] [1629552509.787532, 119178.943000]: setting new goalpoint\n",
                        "[WARN] [1629552509.867526, 119179.562000]: setting new goalpoint\n",
                        "[WARN] [1629552510.841882, 119187.632000]: setting new goalpoint\n",
                        "[WARN] [1629552510.890746, 119188.209000]: setting new goalpoint\n",
                        "[WARN] [1629552511.442941, 119194.589000]: setting new goalpoint\n",
                        "[WARN] [1629552511.496055, 119195.001000]: setting new goalpoint\n",
                        "[WARN] [1629552511.810398, 119198.182000]: setting new goalpoint\n",
                        "[WARN] [1629552511.846612, 119198.579000]: setting new goalpoint\n",
                        "[WARN] [1629552512.209002, 119202.823000]: setting new goalpoint\n",
                        "[WARN] [1629552512.324206, 119204.069000]: setting new goalpoint\n",
                        "[WARN] [1629552512.694774, 119207.070000]: setting new goalpoint\n",
                        "[WARN] [1629552512.770775, 119207.845000]: setting new goalpoint\n",
                        "[WARN] [1629552513.161795, 119212.729000]: setting new goalpoint\n",
                        "[WARN] [1629552513.237481, 119213.550000]: setting new goalpoint\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Evaluierung beendete\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "source": [
                "\n",
                "\n",
                "def log_eval_metrics(step, metrics):\n",
                "  eval_results = (', ').join(\n",
                "      '{} = {:.6f}'.format(name, result) for name, result in metrics.items())\n",
                "  print('step = {0}: {1}'.format(step, eval_results))\n",
                "\n",
                "log_eval_metrics(0, metrics)\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "step = 0: AverageReturn = -99.793251, AverageEpisodeLength = 1.100000\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "source": [
                "try:\n",
                "  %%time\n",
                "except:\n",
                "  pass\n",
                "\n",
                "\n",
                "# Reset the train step\n",
                "tf_agent.train_step_counter.assign(0)\n",
                "\n",
                "# Evaluate the agent's policy once before training.\n",
                "avg_return = get_eval_metrics()[\"AverageReturn\"]\n",
                "returns = [avg_return]\n",
                "i =0\n",
                "for _ in range(num_iterations):\n",
                "  # Training.\n",
                "  i +=1\n",
                "  collect_actor.run()\n",
                "  loss_info = agent_learner.run(iterations=1)\n",
                "  \n",
                "  # Evaluating.\n",
                "  step = agent_learner.train_step_numpy\n",
                "  if eval_interval and step % eval_interval == 0:\n",
                "    metrics = get_eval_metrics()\n",
                "    log_eval_metrics(step, metrics)\n",
                "    returns.append(metrics[\"AverageReturn\"])\n",
                "\n",
                "  if log_interval and step % log_interval == 0:\n",
                "    print('step = {0}: loss = {1}'.format(step, loss_info.loss.numpy()))\n",
                "rb_observer.close()\n",
                "reverb_server.stop()\n",
                "\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Starte evaluierung\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "[WARN] [1629552514.442133, 119226.987000]: setting new goalpoint\n",
                        "[WARN] [1629552514.512253, 119227.565000]: setting new goalpoint\n",
                        "[WARN] [1629552515.268923, 119235.177000]: setting new goalpoint\n",
                        "[WARN] [1629552515.349753, 119236.000000]: setting new goalpoint\n",
                        "[WARN] [1629552515.712586, 119239.032000]: setting new goalpoint\n",
                        "[WARN] [1629552515.775565, 119239.905000]: setting new goalpoint\n",
                        "[WARN] [1629552516.129104, 119242.678000]: setting new goalpoint\n",
                        "[WARN] [1629552516.182198, 119243.179000]: setting new goalpoint\n",
                        "[WARN] [1629552516.484625, 119245.404000]: setting new goalpoint\n",
                        "[WARN] [1629552516.560501, 119246.245000]: setting new goalpoint\n",
                        "[WARN] [1629552516.915466, 119249.688000]: setting new goalpoint\n",
                        "[WARN] [1629552516.979907, 119250.204000]: setting new goalpoint\n",
                        "[WARN] [1629552517.989831, 119258.367000]: setting new goalpoint\n",
                        "[WARN] [1629552518.058604, 119258.971000]: setting new goalpoint\n",
                        "[WARN] [1629552518.901521, 119266.560000]: setting new goalpoint\n",
                        "[WARN] [1629552518.959976, 119267.109000]: setting new goalpoint\n",
                        "[WARN] [1629552520.182460, 119278.276000]: setting new goalpoint\n",
                        "[WARN] [1629552520.260672, 119278.905000]: setting new goalpoint\n",
                        "[WARN] [1629552521.141197, 119287.691000]: setting new goalpoint\n",
                        "[WARN] [1629552521.188153, 119288.000000]: setting new goalpoint\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Evaluierung beendete\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "[WARN] [1629552521.742846, 119291.506000]: setting new goalpoint\n",
                        "[reverb/cc/client.cc:162] Sampler and server are owned by the same process (1250216) so Table uniform_table is accessed directly without gRPC.\n",
                        "[reverb/cc/client.cc:162] Sampler and server are owned by the same process (1250216) so Table uniform_table is accessed directly without gRPC.\n",
                        "[reverb/cc/client.cc:162] Sampler and server are owned by the same process (1250216) so Table uniform_table is accessed directly without gRPC.\n",
                        "[reverb/cc/client.cc:162] Sampler and server are owned by the same process (1250216) so Table uniform_table is accessed directly without gRPC.\n",
                        "[reverb/cc/client.cc:162] Sampler and server are owned by the same process (1250216) so Table uniform_table is accessed directly without gRPC.\n",
                        "[reverb/cc/client.cc:162] Sampler and server are owned by the same process (1250216) so Table uniform_table is accessed directly without gRPC.\n",
                        "[WARN] [1629552527.717961, 119340.059000]: setting new goalpoint\n",
                        "[WARN] [1629552528.105548, 119342.739000]: setting new goalpoint\n",
                        "[WARN] [1629552528.179678, 119343.427000]: setting new goalpoint\n",
                        "[WARN] [1629552528.522571, 119346.697000]: setting new goalpoint\n",
                        "[WARN] [1629552528.601402, 119347.295000]: setting new goalpoint\n",
                        "[WARN] [1629552528.960984, 119349.937000]: setting new goalpoint\n",
                        "[WARN] [1629552529.032313, 119350.703000]: setting new goalpoint\n",
                        "[WARN] [1629552530.103371, 119360.295000]: setting new goalpoint\n",
                        "[WARN] [1629552530.175841, 119360.959000]: setting new goalpoint\n",
                        "[WARN] [1629552531.107594, 119369.774000]: setting new goalpoint\n",
                        "[WARN] [1629552531.189938, 119370.560000]: setting new goalpoint\n",
                        "[WARN] [1629552531.553632, 119373.193000]: setting new goalpoint\n",
                        "[WARN] [1629552531.639565, 119373.519000]: setting new goalpoint\n",
                        "\u001b[33m[ WARN] [1629552532.046853422, 119376.303000000]: Fail: ABORTED: No motion plan found. No execution attempted.\u001b[0m\n",
                        "[WARN] [1629552532.241089, 119377.751000]: setting new goalpoint\n",
                        "[WARN] [1629552532.324659, 119378.282000]: setting new goalpoint\n",
                        "[WARN] [1629552533.264066, 119386.889000]: setting new goalpoint\n",
                        "[WARN] [1629552533.344197, 119387.521000]: setting new goalpoint\n",
                        "[WARN] [1629552533.891298, 119393.418000]: setting new goalpoint\n",
                        "[WARN] [1629552533.956498, 119393.954000]: setting new goalpoint\n",
                        "[WARN] [1629552534.292299, 119398.114000]: setting new goalpoint\n",
                        "[WARN] [1629552534.367935, 119398.584000]: setting new goalpoint\n",
                        "[WARN] [1629552535.438063, 119406.588000]: setting new goalpoint\n",
                        "[WARN] [1629552535.497428, 119406.926000]: setting new goalpoint\n",
                        "[WARN] [1629552536.326330, 119414.723000]: setting new goalpoint\n",
                        "[WARN] [1629552536.388709, 119415.198000]: setting new goalpoint\n",
                        "[WARN] [1629552536.765131, 119417.837000]: setting new goalpoint\n",
                        "[WARN] [1629552536.837513, 119418.532000]: setting new goalpoint\n",
                        "[WARN] [1629552537.141253, 119421.652000]: setting new goalpoint\n",
                        "[WARN] [1629552537.219550, 119422.509000]: setting new goalpoint\n",
                        "[WARN] [1629552537.539326, 119424.797000]: setting new goalpoint\n",
                        "[WARN] [1629552537.642570, 119425.730000]: setting new goalpoint\n",
                        "[WARN] [1629552537.973078, 119429.069000]: setting new goalpoint\n",
                        "[WARN] [1629552538.035437, 119429.497000]: setting new goalpoint\n",
                        "[WARN] [1629552538.451638, 119432.600000]: setting new goalpoint\n",
                        "[WARN] [1629552538.520289, 119433.214000]: setting new goalpoint\n",
                        "[WARN] [1629552538.799991, 119435.510000]: setting new goalpoint\n",
                        "[WARN] [1629552538.881994, 119436.335000]: setting new goalpoint\n",
                        "[WARN] [1629552539.168956, 119438.850000]: setting new goalpoint\n",
                        "[WARN] [1629552539.254734, 119439.713000]: setting new goalpoint\n",
                        "[WARN] [1629552540.305418, 119450.036000]: setting new goalpoint\n",
                        "[WARN] [1629552540.392188, 119451.066000]: setting new goalpoint\n",
                        "[WARN] [1629552541.021304, 119457.415000]: setting new goalpoint\n",
                        "[WARN] [1629552541.123868, 119458.268000]: setting new goalpoint\n",
                        "\u001b[33m[ WARN] [1629552542.060064718, 119467.566000000]: Fail: ABORTED: No motion plan found. No execution attempted.\u001b[0m\n",
                        "[WARN] [1629552542.246804, 119469.166000]: setting new goalpoint\n",
                        "[WARN] [1629552542.339753, 119469.777000]: setting new goalpoint\n",
                        "[WARN] [1629552542.998551, 119475.394000]: setting new goalpoint\n",
                        "[WARN] [1629552543.136936, 119477.188000]: setting new goalpoint\n",
                        "[WARN] [1629552543.506302, 119480.515000]: setting new goalpoint\n",
                        "[WARN] [1629552543.559806, 119480.839000]: setting new goalpoint\n",
                        "[WARN] [1629552543.900952, 119483.549000]: setting new goalpoint\n",
                        "[WARN] [1629552543.983836, 119484.310000]: setting new goalpoint\n",
                        "[WARN] [1629552544.315204, 119487.087000]: setting new goalpoint\n",
                        "[WARN] [1629552544.369034, 119487.490000]: setting new goalpoint\n",
                        "[WARN] [1629552545.251999, 119496.144000]: setting new goalpoint\n",
                        "[WARN] [1629552545.343321, 119496.696000]: setting new goalpoint\n",
                        "[WARN] [1629552546.037340, 119503.678000]: setting new goalpoint\n",
                        "[WARN] [1629552546.130006, 119504.814000]: setting new goalpoint\n",
                        "[WARN] [1629552546.525803, 119507.351000]: setting new goalpoint\n",
                        "[WARN] [1629552546.584646, 119507.751000]: setting new goalpoint\n",
                        "[WARN] [1629552546.933583, 119511.472000]: setting new goalpoint\n",
                        "[WARN] [1629552546.994346, 119512.062000]: setting new goalpoint\n",
                        "[WARN] [1629552547.349673, 119515.291000]: setting new goalpoint\n",
                        "[WARN] [1629552547.423293, 119515.931000]: setting new goalpoint\n",
                        "[WARN] [1629552547.796595, 119519.146000]: setting new goalpoint\n",
                        "[WARN] [1629552547.898856, 119520.090000]: setting new goalpoint\n",
                        "[WARN] [1629552548.232259, 119523.065000]: setting new goalpoint\n",
                        "[WARN] [1629552548.282326, 119523.399000]: setting new goalpoint\n",
                        "[WARN] [1629552549.296052, 119531.438000]: setting new goalpoint\n",
                        "[WARN] [1629552549.375641, 119532.225000]: setting new goalpoint\n",
                        "[WARN] [1629552551.717464, 119553.685000]: setting new goalpoint\n",
                        "[WARN] [1629552551.778920, 119554.269000]: setting new goalpoint\n",
                        "[WARN] [1629552552.503544, 119560.236000]: setting new goalpoint\n",
                        "[WARN] [1629552552.603974, 119561.096000]: setting new goalpoint\n",
                        "[WARN] [1629552552.981354, 119564.285000]: setting new goalpoint\n",
                        "[WARN] [1629552553.049436, 119564.777000]: setting new goalpoint\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "step = 50: loss = 5841.31884765625\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "\u001b[33m[ WARN] [1629552553.441187533, 119568.157000000]: Fail: ABORTED: No motion plan found. No execution attempted.\u001b[0m\n",
                        "[WARN] [1629552553.708614, 119570.433000]: setting new goalpoint\n",
                        "[WARN] [1629552553.794410, 119571.136000]: setting new goalpoint\n",
                        "[WARN] [1629552554.086566, 119573.343000]: setting new goalpoint\n",
                        "[WARN] [1629552554.160800, 119574.256000]: setting new goalpoint\n",
                        "[WARN] [1629552555.203023, 119583.674000]: setting new goalpoint\n",
                        "[WARN] [1629552555.277044, 119584.145000]: setting new goalpoint\n",
                        "[WARN] [1629552556.611726, 119597.995000]: setting new goalpoint\n",
                        "[WARN] [1629552556.681014, 119598.694000]: setting new goalpoint\n",
                        "[WARN] [1629552560.057643, 119630.782000]: setting new goalpoint\n",
                        "[WARN] [1629552560.133883, 119631.607000]: setting new goalpoint\n",
                        "[WARN] [1629552560.867154, 119638.540000]: setting new goalpoint\n",
                        "[WARN] [1629552560.930312, 119639.162000]: setting new goalpoint\n",
                        "\u001b[33m[ WARN] [1629552567.341648833, 119650.084000000]: Fail: ABORTED: No motion plan found. No execution attempted.\u001b[0m\n",
                        "[WARN] [1629552572.118629, 119655.118200]: setting new goalpoint\n",
                        "[WARN] [1629552572.210243, 119655.209800]: setting new goalpoint\n",
                        "[WARN] [1629552575.912196, 119659.605400]: setting new goalpoint\n",
                        "[WARN] [1629552575.986956, 119659.694300]: setting new goalpoint\n",
                        "[WARN] [1629552576.410592, 119660.027100]: setting new goalpoint\n",
                        "[WARN] [1629552576.479129, 119660.080800]: setting new goalpoint\n",
                        "[WARN] [1629552579.413551, 119663.460000]: setting new goalpoint\n",
                        "[WARN] [1629552579.500204, 119663.549100]: setting new goalpoint\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Starte evaluierung\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "[WARN] [1629552637.190812, 119909.794600]: setting new goalpoint\n",
                        "[WARN] [1629552637.236885, 119910.321600]: setting new goalpoint\n",
                        "[WARN] [1629552691.332552, 120404.559600]: setting new goalpoint\n",
                        "\u001b[31m[ERROR] [1629552698.025794724, 120466.382600000]: Got a callback on a goalHandle that we're not tracking.                 This is an internal SimpleActionClient/ActionClient bug.                 This could also be a GoalID collision\u001b[0m\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "\n",
                "steps = range(0, num_iterations + 1, eval_interval)\n",
                "plt.plot(steps, returns)\n",
                "plt.ylabel('Average Return')\n",
                "plt.xlabel('Step')\n",
                "plt.ylim()\n",
                "returns"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "get_eval_metrics()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "plt.scatter(steps,returns)"
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        },
        "interpreter": {
            "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.8",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}