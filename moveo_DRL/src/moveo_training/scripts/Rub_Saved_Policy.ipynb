{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import sys\n",
    "sys.executable\n",
    "import os\n",
    "os.getcwd()\n",
    "sys.path.append('devel/lib/python3/dist-packages/theconstruct_msgs/msg/')\n",
    "sys.path.append('/home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/src')\n",
    "sys.path.append('/home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/src/moveo_training/scripts')\n",
    "sys.path.append('/home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/devel/lib/python3/dist-packages/openai_ros/msg')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import base64\n",
    "import imageio\n",
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import reverb\n",
    "import tempfile\n",
    "import PIL.Image\n",
    "\n",
    "import tensorflow as tf\n",
    "import moveo_inverse_kinematic\n",
    "from tf_agents.agents.ddpg import critic_network\n",
    "from tf_agents.agents.sac import sac_agent\n",
    "from tf_agents.agents.sac import tanh_normal_projection_network\n",
    "from tf_agents.environments import suite_pybullet\n",
    "from tf_agents.metrics import py_metrics\n",
    "from tf_agents.networks import actor_distribution_network\n",
    "from tf_agents.policies import greedy_policy\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.policies import random_py_policy\n",
    "from tf_agents.policies import py_tf_policy\n",
    "from tf_agents.replay_buffers import reverb_replay_buffer\n",
    "from tf_agents.replay_buffers import reverb_utils\n",
    "from tf_agents.train import actor\n",
    "from tf_agents.train import learner\n",
    "from tf_agents.train import triggers\n",
    "from tf_agents.train.utils import spec_utils\n",
    "from tf_agents.train.utils import strategy_utils\n",
    "from tf_agents.train.utils import train_utils\n",
    "import rospy\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.train.utils import strategy_utils\n",
    "tempdir = tempfile.gettempdir()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rospy.init_node(\"train_moveo\")\n",
    "env_name = 'MoveoIK-v0' # @param {type:\"string\"}\n",
    "env = suite_gym.load(env_name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "policy_dir =\"~/Documents/policies/collect_policy\"\n",
    "eager_py_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "    policy_dir, env.time_step_spec(), env.action_spec())\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "# eager_py_policy.action(time_step)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "time_step = env.reset()\n",
    "initial_collect_actor = actor.Actor(\n",
    "  env,\n",
    "  eager_py_policy,\n",
    "  time_step,\n",
    "  steps_per_run=1,\n",
    "  )\n",
    "initial_collect_actor.run()\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}