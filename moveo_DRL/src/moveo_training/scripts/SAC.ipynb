{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "import base64\n",
                "#import imageio\n",
                "import IPython\n",
                "import matplotlib.pyplot as plt\n",
                "import os\n",
                "# import reverb\n",
                "import tempfile\n",
                "#import PIL.Image"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "import sys\n",
                "import os\n",
                "sys.modules[__name__]\n",
                "sys.path.append(\"/home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/src\")\n",
                "sys.path.append(\"/home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/devel/lib/python3/dist-packages\")\n",
                "sys.path.append(\"/home/nils/anaconda3/bin/python\")\n",
                "print(os.getcwd())\n",
                "print(sys.executable)\n",
                "print(sys.path)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "/tf\n",
                        "/usr/bin/python3\n",
                        "['/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.6/dist-packages/IPython/extensions', '/root/.ipython', '/home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/src', '/home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/devel/lib/python3/dist-packages', '/home/nils/anaconda3/bin/python']\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "source": [
                "import tensorflow as tf\n",
                "from tf_agents.environments import suite_gym\n",
                "from tf_agents.agents.ddpg import critic_network\n",
                "from tf_agents.agents.sac import sac_agent\n",
                "from tf_agents.agents.sac import tanh_normal_projection_network\n",
                "from tf_agents.environments import suite_pybullet\n",
                "from tf_agents.metrics import py_metrics\n",
                "from tf_agents.networks import actor_distribution_network\n",
                "from tf_agents.policies import greedy_policy\n",
                "from tf_agents.policies import py_tf_eager_policy\n",
                "from tf_agents.policies import random_py_policy\n",
                "from tf_agents.replay_buffers import reverb_replay_buffer\n",
                "from tf_agents.replay_buffers import reverb_utils\n",
                "from tf_agents.train import actor\n",
                "from tf_agents.train import learner\n",
                "from tf_agents.train import triggers\n",
                "from tf_agents.train.utils import spec_utils\n",
                "from tf_agents.train.utils import strategy_utils\n",
                "from tf_agents.train.utils import train_utils\n",
                "import rospy\n",
                "import tempfile\n",
                "\n",
                "import moveo_training.scripts.moveo_inverse_kinematic\n",
                "\n",
                "tempdir = tempfile.gettempdir()"
            ],
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "ModuleNotFoundError",
                    "evalue": "No module named 'tf_agents'",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-7-78b815abe658>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtf_agents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironments\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msuite_gym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mddpg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcritic_network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msac\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msac_agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tf_agents'"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "source": [
                "rospy.init_node(\"train_moveo_her\")\n",
                "env_name = 'MoveoIK-v0' # @param {type:\"string\"}\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "source": [
                "# Use \"num_iterations = 1e6\" for better results (2 hrs)\n",
                "# 1e5 is just so this doesn't take too long (1 hr)\n",
                "num_iterations = 100000 # @param {type:\"integer\"}\n",
                "\n",
                "initial_collect_steps = 10 # @param {type:\"integer\"}\n",
                "collect_steps_per_iteration = 1 # @param {type:\"integer\"}\n",
                "replay_buffer_capacity = 10000 # @param {type:\"integer\"}\n",
                "\n",
                "batch_size = 256 # @param {type:\"integer\"}\n",
                "\n",
                "critic_learning_rate = 3e-4 # @param {type:\"number\"}\n",
                "actor_learning_rate = 3e-4 # @param {type:\"number\"}\n",
                "alpha_learning_rate = 3e-4 # @param {type:\"number\"}\n",
                "target_update_tau = 0.005 # @param {type:\"number\"}\n",
                "target_update_period = 1 # @param {type:\"number\"}\n",
                "gamma = 0.99 # @param {type:\"number\"}\n",
                "reward_scale_factor = 1.0 # @param {type:\"number\"}\n",
                "\n",
                "actor_fc_layer_params = (256, 256)\n",
                "critic_joint_fc_layer_params = (256, 256)\n",
                "\n",
                "log_interval = 5000 # @param {type:\"integer\"}\n",
                "\n",
                "num_eval_episodes = 1 # @param {type:\"integer\"}\n",
                "eval_interval = 10000 # @param {type:\"integer\"}\n",
                "\n",
                "policy_save_interval = 5000 # @param {type:\"integer\"}"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "source": [
                "\n",
                "import gym\n",
                "env_dict = gym.envs.registration.registry.env_specs.copy()\n",
                "for env in env_dict:\n",
                "    if env_name in env:\n",
                "        print(\"Remove {} from registry\".format(env))\n",
                "        del gym.envs.registration.registry.env_specs[env]\n",
                "\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Remove MoveoIK-v0 from registry\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "source": [
                "from gym.envs.registration import register\n",
                "register(\n",
                "        id='MoveoIK-v0',\n",
                "        entry_point='moveo_training.scripts.moveo_inverse_kinematic:MoveoIKEnv',\n",
                "        max_episode_steps=100,\n",
                "    )\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "source": [
                "env = suite_gym.load(env_name)\n",
                "env.reset()"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "###### Setting Group Moveit with 30 seconds wait...\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "[ERROR] [1628592267.434938, 0.000000]: NOT Initialising Simulation Physics Parameters\n",
                        "[WARN] [1628592267.439516, 0.000000]: Start Init ControllersConnection\n",
                        "[WARN] [1628592267.441013, 0.000000]: END Init ControllersConnection\n",
                        "/home/nils/.local/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
                        "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Trying to set traj\n"
                    ]
                },
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "TimeStep(\n",
                            "{'discount': array(1., dtype=float32),\n",
                            " 'observation': array([0.56698257], dtype=float32),\n",
                            " 'reward': array(0., dtype=float32),\n",
                            " 'step_type': array(0, dtype=int32)})"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 18
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "source": [
                "collect_env = suite_gym.load(env_name)\n",
                "eval_env = suite_gym.load(env_name)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "###### Setting Group Moveit with 30 seconds wait...\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "[ERROR] [1628592268.258598, 0.000000]: NOT Initialising Simulation Physics Parameters\n",
                        "[WARN] [1628592268.266199, 0.000000]: Start Init ControllersConnection\n",
                        "[WARN] [1628592268.267496, 0.000000]: END Init ControllersConnection\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "###### Setting Group Moveit with 30 seconds wait...\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "[ERROR] [1628592268.667965, 0.000000]: NOT Initialising Simulation Physics Parameters\n",
                        "[WARN] [1628592268.676959, 0.000000]: Start Init ControllersConnection\n",
                        "[WARN] [1628592268.678343, 0.000000]: END Init ControllersConnection\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "source": [
                "use_gpu = True"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "source": [
                "strategy = strategy_utils.get_strategy(tpu=False, use_gpu=use_gpu)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
                        "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
                        "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "2021-08-10 12:44:28.803489: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
                        "2021-08-10 12:44:28.837823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
                        "2021-08-10 12:44:28.838215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
                        "pciBusID: 0000:01:00.0 name: GeForce GTX 970 computeCapability: 5.2\n",
                        "coreClock: 1.2155GHz coreCount: 13 deviceMemorySize: 3.94GiB deviceMemoryBandwidth: 208.91GiB/s\n",
                        "2021-08-10 12:44:28.838474: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/devel/lib:/opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu\n",
                        "2021-08-10 12:44:28.838577: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/devel/lib:/opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu\n",
                        "2021-08-10 12:44:28.838664: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/devel/lib:/opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu\n",
                        "2021-08-10 12:44:28.838746: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/devel/lib:/opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu\n",
                        "2021-08-10 12:44:28.838826: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/devel/lib:/opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu\n",
                        "2021-08-10 12:44:28.838904: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/devel/lib:/opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu\n",
                        "2021-08-10 12:44:28.839009: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/devel/lib:/opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu\n",
                        "2021-08-10 12:44:28.839138: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/devel/lib:/opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu\n",
                        "2021-08-10 12:44:28.839149: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
                        "Skipping registering GPU devices...\n",
                        "2021-08-10 12:44:28.839707: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
                        "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
                        "2021-08-10 12:44:28.839869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
                        "2021-08-10 12:44:28.839878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "source": [
                "observation_spec, action_spec, time_step_spec = (\n",
                "      spec_utils.get_tensor_specs(collect_env))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "source": [
                "with strategy.scope():\n",
                "  critic_net = critic_network.CriticNetwork(\n",
                "        (observation_spec, action_spec),\n",
                "        observation_fc_layer_params=None,\n",
                "        action_fc_layer_params=None,\n",
                "        joint_fc_layer_params=critic_joint_fc_layer_params,\n",
                "        kernel_initializer='glorot_uniform',\n",
                "        last_kernel_initializer='glorot_uniform')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "source": [
                "with strategy.scope():\n",
                "  actor_net = actor_distribution_network.ActorDistributionNetwork(\n",
                "      observation_spec,\n",
                "      action_spec,\n",
                "      fc_layer_params=actor_fc_layer_params,\n",
                "      continuous_projection_net=(\n",
                "          tanh_normal_projection_network.TanhNormalProjectionNetwork))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "source": [
                "with strategy.scope():\n",
                "  train_step = train_utils.create_train_step()\n",
                "\n",
                "  tf_agent = sac_agent.SacAgent(\n",
                "        time_step_spec,\n",
                "        action_spec,\n",
                "        actor_network=actor_net,\n",
                "        critic_network=critic_net,\n",
                "        actor_optimizer=tf.compat.v1.train.AdamOptimizer(\n",
                "            learning_rate=actor_learning_rate),\n",
                "        critic_optimizer=tf.compat.v1.train.AdamOptimizer(\n",
                "            learning_rate=critic_learning_rate),\n",
                "        alpha_optimizer=tf.compat.v1.train.AdamOptimizer(\n",
                "            learning_rate=alpha_learning_rate),\n",
                "        target_update_tau=target_update_tau,\n",
                "        target_update_period=target_update_period,\n",
                "        td_errors_loss_fn=tf.math.squared_difference,\n",
                "        gamma=gamma,\n",
                "        reward_scale_factor=reward_scale_factor,\n",
                "        train_step_counter=train_step)\n",
                "\n",
                "  tf_agent.initialize()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "source": [
                "rate_limiter=reverb.rate_limiters.SampleToInsertRatio(samples_per_insert=3.0, min_size_to_sample=3, error_buffer=3.0)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "source": [
                "table_name = 'uniform_table'\n",
                "table = reverb.Table(\n",
                "    table_name,\n",
                "    max_size=replay_buffer_capacity,\n",
                "    sampler=reverb.selectors.Uniform(),\n",
                "    remover=reverb.selectors.Fifo(),\n",
                "    rate_limiter=reverb.rate_limiters.MinSize(1))\n",
                "\n",
                "reverb_server = reverb.Server([table])"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "[reverb/cc/platform/tfrecord_checkpointer.cc:150]  Initializing TFRecordCheckpointer in /tmp/tmp1q2zqp0j.\n",
                        "[reverb/cc/platform/tfrecord_checkpointer.cc:378] Loading latest checkpoint from /tmp/tmp1q2zqp0j\n",
                        "[reverb/cc/platform/default/server.cc:54] Started replay server on port 15400\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "source": [
                "reverb_replay = reverb_replay_buffer.ReverbReplayBuffer(\n",
                "    tf_agent.collect_data_spec,\n",
                "    sequence_length=2,\n",
                "    table_name=table_name,\n",
                "    local_server=reverb_server)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "source": [
                "dataset = reverb_replay.as_dataset(\n",
                "      sample_batch_size=batch_size, num_steps=2).prefetch(50)\n",
                "experience_dataset_fn = lambda: dataset"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "source": [
                "\n",
                "tf_eval_policy = tf_agent.policy\n",
                "eval_policy = py_tf_eager_policy.PyTFEagerPolicy(\n",
                "  tf_eval_policy, use_tf_function=True)\n",
                "\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "source": [
                "tf_collect_policy = tf_agent.collect_policy\n",
                "collect_policy = py_tf_eager_policy.PyTFEagerPolicy(\n",
                "  tf_collect_policy, use_tf_function=True)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "source": [
                "\n",
                "\n",
                "random_policy = random_py_policy.RandomPyPolicy(\n",
                "  collect_env.time_step_spec(), collect_env.action_spec())\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "source": [
                "\n",
                "\n",
                "rb_observer = reverb_utils.ReverbAddTrajectoryObserver(\n",
                "  reverb_replay.py_client,\n",
                "  table_name,\n",
                "  sequence_length=2,\n",
                "  stride_length=1)\n",
                "\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "source": [
                "\n",
                "initial_collect_actor = actor.Actor(\n",
                "  collect_env,\n",
                "  random_policy,\n",
                "  train_step,\n",
                "  steps_per_run=initial_collect_steps,\n",
                "  observers=[rb_observer])\n",
                "initial_collect_actor.run()\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Trying to set traj\n",
                        "Trying to set traj\n",
                        "Trying to set traj\n",
                        "Trying to set traj\n",
                        "Trying to set traj\n",
                        "Trying to set traj\n",
                        "Trying to set traj\n",
                        "Trying to set traj\n",
                        "Trying to set traj\n",
                        "Trying to set traj\n",
                        "Trying to set traj\n",
                        "Trying to set traj\n",
                        "Trying to set traj\n",
                        "Trying to set traj\n",
                        "Trying to set traj\n",
                        "Trying to set traj\n",
                        "Trying to set traj\n",
                        "Trying to set traj\n",
                        "Trying to set traj\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "\u001b[33m[ WARN] [1628592485.926166921, 220.615000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame Gripper_Idol_Gear at time 220.606000 according to authority unknown_publisher\u001b[0m\n",
                        "\u001b[33m[ WARN] [1628592485.926213294, 220.615000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame Gripper_Servo_Gear at time 220.606000 according to authority unknown_publisher\u001b[0m\n",
                        "\u001b[33m[ WARN] [1628592485.926233343, 220.615000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame Link_1 at time 220.606000 according to authority unknown_publisher\u001b[0m\n",
                        "\u001b[33m[ WARN] [1628592485.926254812, 220.615000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame Link_2 at time 220.606000 according to authority unknown_publisher\u001b[0m\n",
                        "\u001b[33m[ WARN] [1628592485.926542428, 220.615000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame Link_3 at time 220.606000 according to authority unknown_publisher\u001b[0m\n",
                        "\u001b[33m[ WARN] [1628592485.926576142, 220.615000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame Link_4 at time 220.606000 according to authority unknown_publisher\u001b[0m\n",
                        "\u001b[33m[ WARN] [1628592485.926752255, 220.615000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame Link_5 at time 220.606000 according to authority unknown_publisher\u001b[0m\n",
                        "\u001b[33m[ WARN] [1628592485.926779501, 220.615000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame Pivot_Arm_Gripper_Idol at time 220.606000 according to authority unknown_publisher\u001b[0m\n",
                        "\u001b[33m[ WARN] [1628592485.926794409, 220.615000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame Tip_Gripper_Idol at time 220.606000 according to authority unknown_publisher\u001b[0m\n",
                        "\u001b[33m[ WARN] [1628592485.926807718, 220.615000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame Tip_Gripper_Servo at time 220.606000 according to authority unknown_publisher\u001b[0m\n",
                        "\u001b[33m[ WARN] [1628592548.714211587, 282.847000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame Gripper_Idol_Gear at time 282.806000 according to authority unknown_publisher\u001b[0m\n",
                        "\u001b[33m[ WARN] [1628592548.714278219, 282.847000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame Gripper_Servo_Gear at time 282.806000 according to authority unknown_publisher\u001b[0m\n",
                        "\u001b[33m[ WARN] [1628592548.714315261, 282.847000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame Link_1 at time 282.806000 according to authority unknown_publisher\u001b[0m\n",
                        "\u001b[33m[ WARN] [1628592548.714343935, 282.847000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame Link_2 at time 282.806000 according to authority unknown_publisher\u001b[0m\n",
                        "\u001b[33m[ WARN] [1628592548.714374813, 282.847000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame Link_3 at time 282.806000 according to authority unknown_publisher\u001b[0m\n",
                        "\u001b[33m[ WARN] [1628592548.714398744, 282.847000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame Link_4 at time 282.806000 according to authority unknown_publisher\u001b[0m\n",
                        "\u001b[33m[ WARN] [1628592548.714419969, 282.847000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame Link_5 at time 282.806000 according to authority unknown_publisher\u001b[0m\n",
                        "\u001b[33m[ WARN] [1628592548.714465816, 282.847000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame Pivot_Arm_Gripper_Idol at time 282.806000 according to authority unknown_publisher\u001b[0m\n",
                        "\u001b[33m[ WARN] [1628592548.714488888, 282.847000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame Tip_Gripper_Idol at time 282.806000 according to authority unknown_publisher\u001b[0m\n",
                        "\u001b[33m[ WARN] [1628592548.714516325, 282.847000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame Tip_Gripper_Servo at time 282.806000 according to authority unknown_publisher\u001b[0m\n",
                        "\u001b[33m[ WARN] [1628592622.330172665, 355.534000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame Gripper_Idol_Gear at time 355.506000 according to authority unknown_publisher\u001b[0m\n",
                        "\u001b[33m[ WARN] [1628592622.330235343, 355.534000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame Gripper_Servo_Gear at time 355.506000 according to authority unknown_publisher\u001b[0m\n",
                        "\u001b[33m[ WARN] [1628592622.330262645, 355.534000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame Link_1 at time 355.506000 according to authority unknown_publisher\u001b[0m\n",
                        "\u001b[33m[ WARN] [1628592622.330287009, 355.534000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame Link_2 at time 355.506000 according to authority unknown_publisher\u001b[0m\n",
                        "\u001b[33m[ WARN] [1628592622.330306546, 355.534000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame Link_3 at time 355.506000 according to authority unknown_publisher\u001b[0m\n",
                        "\u001b[33m[ WARN] [1628592622.330329393, 355.534000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame Link_4 at time 355.506000 according to authority unknown_publisher\u001b[0m\n",
                        "\u001b[33m[ WARN] [1628592622.330348307, 355.534000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame Link_5 at time 355.506000 according to authority unknown_publisher\u001b[0m\n",
                        "\u001b[33m[ WARN] [1628592622.330367642, 355.534000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame Pivot_Arm_Gripper_Idol at time 355.506000 according to authority unknown_publisher\u001b[0m\n",
                        "\u001b[33m[ WARN] [1628592622.330385470, 355.534000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame Tip_Gripper_Idol at time 355.506000 according to authority unknown_publisher\u001b[0m\n",
                        "\u001b[33m[ WARN] [1628592622.330403210, 355.534000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame Tip_Gripper_Servo at time 355.506000 according to authority unknown_publisher\u001b[0m\n",
                        "[reverb/cc/platform/default/server.cc:63] Shutting down replay server\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "\n",
                "\n",
                "env_step_metric = py_metrics.EnvironmentSteps()\n",
                "collect_actor = actor.Actor(\n",
                "  collect_env,\n",
                "  collect_policy,\n",
                "  train_step,\n",
                "  steps_per_run=1,\n",
                "  metrics=actor.collect_metrics(10),\n",
                "  summary_dir=os.path.join(tempdir, learner.TRAIN_DIR),\n",
                "  observers=[rb_observer, env_step_metric])\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "eval_actor = actor.Actor(\n",
                "  eval_env,\n",
                "  eval_policy,\n",
                "  train_step,\n",
                "  episodes_per_run=num_eval_episodes,\n",
                "  metrics=actor.eval_metrics(num_eval_episodes),\n",
                "  summary_dir=os.path.join(tempdir, 'eval'),\n",
                ")\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "\n",
                "\n",
                "saved_model_dir = os.path.join(tempdir, learner.POLICY_SAVED_MODEL_DIR)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "\n",
                "# Triggers to save the agent's policy checkpoints.\n",
                "learning_triggers = [\n",
                "    triggers.PolicySavedModelTrigger(\n",
                "        saved_model_dir,\n",
                "        tf_agent,\n",
                "        train_step,\n",
                "        interval=policy_save_interval),\n",
                "    triggers.StepPerSecondLogTrigger(train_step, interval=1000),\n",
                "]\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "\n",
                "agent_learner = learner.Learner(\n",
                "  tempdir,\n",
                "  train_step,\n",
                "  tf_agent,\n",
                "  experience_dataset_fn,\n",
                "  triggers=learning_triggers)\n",
                "\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "\n",
                "def get_eval_metrics():\n",
                "  print(\"Starte evaluierung\")\n",
                "  eval_actor.run()\n",
                "  results = {}\n",
                "  for metric in eval_actor.metrics:\n",
                "    results[metric.name] = metric.result()\n",
                "  print(\"Evaluierung beendete\")\n",
                "  return results\n",
                "\n",
                "metrics = get_eval_metrics()\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "\n",
                "\n",
                "def log_eval_metrics(step, metrics):\n",
                "  eval_results = (', ').join(\n",
                "      '{} = {:.6f}'.format(name, result) for name, result in metrics.items())\n",
                "  print('step = {0}: {1}'.format(step, eval_results))\n",
                "\n",
                "log_eval_metrics(0, metrics)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "\n",
                "\n",
                "# Reset the train step\n",
                "tf_agent.train_step_counter.assign(0)\n",
                "\n",
                "# Evaluate the agent's policy once before training.\n",
                "avg_return = get_eval_metrics()[\"AverageReturn\"]\n",
                "returns = [avg_return]\n",
                "\n",
                "for _ in range(num_iterations):\n",
                "  # Training.\n",
                "  print(\"Hallo ich bin noch am trainineren\")\n",
                "  collect_actor.run()\n",
                "  loss_info = agent_learner.run(iterations=1)\n",
                "  \n",
                "  # Evaluating.\n",
                "  step = agent_learner.train_step_numpy\n",
                "\n",
                "  if eval_interval and step % eval_interval == 0:\n",
                "    metrics = get_eval_metrics()\n",
                "    log_eval_metrics(step, metrics)\n",
                "    returns.append(metrics[\"AverageReturn\"])\n",
                "\n",
                "  if log_interval and step % log_interval == 0:\n",
                "    print('step = {0}: loss = {1}'.format(step, loss_info.loss.numpy()))\n"
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3",
            "language": "python"
        },
        "interpreter": {
            "hash": "d0b14f7a84566a43528cf611731f7edd5c8e6dc2af952cf56f49f145d306d43e"
        },
        "language_info": {
            "name": "python",
            "version": "3.6.9",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}