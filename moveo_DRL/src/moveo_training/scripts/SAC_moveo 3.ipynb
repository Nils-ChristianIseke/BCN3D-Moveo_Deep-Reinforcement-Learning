{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "import sys\n",
                "sys.executable\n",
                "import os\n",
                "os.getcwd()\n",
                "sys.path.append('devel/lib/python3/dist-packages/theconstruct_msgs/msg/')\n",
                "sys.path.append('/home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/src')\n",
                "sys.path.append('/home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/src/moveo_training/scripts')\n",
                "sys.path.append('/home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/devel/lib/python3/dist-packages/openai_ros/msg')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "sys.path"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "['/home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL',\n",
                            " '',\n",
                            " '/home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/devel/lib/python3/dist-packages',\n",
                            " '/opt/ros/noetic/lib/python3/dist-packages',\n",
                            " '/home/nils/anaconda3/lib/python38.zip',\n",
                            " '/home/nils/anaconda3/lib/python3.8',\n",
                            " '/home/nils/anaconda3/lib/python3.8/lib-dynload',\n",
                            " '/home/nils/.local/lib/python3.8/site-packages',\n",
                            " '/home/nils/anaconda3/lib/python3.8/site-packages',\n",
                            " '/home/nils/anaconda3/lib/python3.8/site-packages/locket-0.2.1-py3.8.egg',\n",
                            " '/home/nils/.local/lib/python3.8/site-packages/IPython/extensions',\n",
                            " '/home/nils/.ipython',\n",
                            " 'devel/lib/python3/dist-packages/theconstruct_msgs/msg/',\n",
                            " '/home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/src',\n",
                            " '/home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/src/moveo_training/scripts',\n",
                            " '/home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/devel/lib/python3/dist-packages/openai_ros/msg']"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 2
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "import base64\n",
                "import imageio\n",
                "import IPython\n",
                "import matplotlib.pyplot as plt\n",
                "import os\n",
                "import reverb\n",
                "import tempfile\n",
                "import PIL.Image\n",
                "\n",
                "import tensorflow as tf\n",
                "import moveo_inverse_kinematic\n",
                "from tf_agents.environments import suite_gym\n",
                "from tf_agents.agents.ddpg import critic_network\n",
                "from tf_agents.agents.sac import sac_agent\n",
                "from tf_agents.agents.sac import tanh_normal_projection_network\n",
                "from tf_agents.environments import suite_pybullet\n",
                "from tf_agents.metrics import py_metrics\n",
                "from tf_agents.networks import actor_distribution_network\n",
                "from tf_agents.policies import greedy_policy\n",
                "from tf_agents.policies import py_tf_eager_policy\n",
                "from tf_agents.policies import random_py_policy\n",
                "from tf_agents.policies import policy_saver\n",
                "from tf_agents.policies import tf_py_policy\n",
                "from tf_agents.replay_buffers import reverb_replay_buffer\n",
                "from tf_agents.replay_buffers import reverb_utils\n",
                "from tf_agents.train import actor\n",
                "from tf_agents.train import learner\n",
                "from tf_agents.train import triggers\n",
                "from tf_agents.train.utils import spec_utils\n",
                "from tf_agents.train.utils import strategy_utils\n",
                "from tf_agents.train.utils import train_utils\n",
                "\n",
                "import rospy\n",
                "from gym.envs.registration import register\n",
                "import gym\n",
                "tempdir = tempfile.gettempdir()\n",
                "from tf_agents.policies import policy_saver\n",
                "from tf_agents.policies import tf_py_policy\n",
                "from tf_agents.utils import common\n",
                "\n",
                "from tf_agents.metrics import tf_metrics"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "2021-08-26 09:03:34.296866: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/devel/lib:/opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu\n",
                        "2021-08-26 09:03:34.296886: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Failed to import pyassimp, see https://github.com/ros-planning/moveit/issues/86 for more info\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "num_iterations = 10000 # @param {type:\"integer\"}\n",
                "\n",
                "initial_collect_steps = 1# @param {type:\"integer\"}\n",
                "collect_steps_per_iteration = 10# @param {type:\"integer\"}\n",
                "replay_buffer_capacity = 1000 # @param {type:\"integer\"}\n",
                "\n",
                "batch_size = 256 # @param {type:\"integer\"}\n",
                "\n",
                "critic_learning_rate = 3e-4 # @param {type:\"number\"}\n",
                "actor_learning_rate = 3e-4 # @param {type:\"number\"}\n",
                "alpha_learning_rate = 3e-4 # @param {type:\"number\"}\n",
                "target_update_tau = 0.005 # @param {type:\"number\"}\n",
                "target_update_period = 1 # @param {type:\"number\"}\n",
                "gamma = 0.99 # @param {type:\"number\"}\n",
                "reward_scale_factor = 1.0 # @param {type:\"number\"}\n",
                "\n",
                "actor_fc_layer_params = (256, 256)\n",
                "critic_joint_fc_layer_params = (256, 256)\n",
                "\n",
                "log_interval = 100# @param {type:\"integer\"}\n",
                "\n",
                "num_eval_episodes = 1# @param {type:\"integer\"}\n",
                "eval_interval = 50 # @param {type:\"integer\"}\n",
                "\n",
                "policy_save_interval = 1000 # @param {type:\"integer\"}\n",
                "\n",
                "\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "summaries_flush_secs=10,"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "source": [
                "\n",
                "rospy.init_node(\"train_moveo\")\n",
                "env_name = 'MoveoIK-v0' # @param {type:\"string\"}\n",
                "env = suite_gym.load('MoveoIK-v0')\n",
                "env.reset()"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "###### Setting Group Moveit with 30 seconds wait...\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "[ERROR] [1629961421.347893, 28433.441000]: NOT Initialising Simulation Physics Parameters\n",
                        "[WARN] [1629961421.378479, 28435.011000]: Start Init ControllersConnection\n",
                        "[WARN] [1629961421.385777, 28435.011000]: END Init ControllersConnection\n",
                        "/home/nils/.local/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
                        "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
                    ]
                },
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "TimeStep(\n",
                            "{'discount': array(1., dtype=float32),\n",
                            " 'observation': array([0.5669771, 0.3      , 0.3      , 0.3      ], dtype=float32),\n",
                            " 'reward': array(0., dtype=float32),\n",
                            " 'step_type': array(0, dtype=int32)})"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 6
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "source": [
                "print('Observation Spec:')\n",
                "print(env.time_step_spec().observation)\n",
                "print('Action Spec:')\n",
                "print(env.action_spec())"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Observation Spec:\n",
                        "BoundedArraySpec(shape=(4,), dtype=dtype('float32'), name='observation', minimum=[ 0. -1. -1. -1.], maximum=[2. 1. 1. 1.])\n",
                        "Action Spec:\n",
                        "BoundedArraySpec(shape=(5,), dtype=dtype('float32'), name='action', minimum=-2.3559999465942383, maximum=2.3559999465942383)\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "source": [
                "collect_env = suite_gym.load(env_name)\n",
                "eval_env = suite_gym.load(env_name)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "###### Setting Group Moveit with 30 seconds wait...\n",
                        "###### Setting Group Moveit with 30 seconds wait...\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "[ERROR] [1629961422.489369, 28486.471000]: NOT Initialising Simulation Physics Parameters\n",
                        "[WARN] [1629961422.510162, 28487.141000]: Start Init ControllersConnection\n",
                        "[WARN] [1629961422.511838, 28487.141000]: END Init ControllersConnection\n",
                        "[ERROR] [1629961422.628200, 28489.391000]: NOT Initialising Simulation Physics Parameters\n",
                        "[WARN] [1629961422.649195, 28490.041000]: Start Init ControllersConnection\n",
                        "[WARN] [1629961422.651319, 28490.161000]: END Init ControllersConnection\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "source": [
                "use_gpu = True\n",
                "strategy = strategy_utils.get_strategy(tpu=False, use_gpu=use_gpu)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
                        "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
                        "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "2021-08-26 09:03:42.714295: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
                        "2021-08-26 09:03:42.743828: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
                        "2021-08-26 09:03:42.744217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
                        "pciBusID: 0000:01:00.0 name: GeForce GTX 970 computeCapability: 5.2\n",
                        "coreClock: 1.2155GHz coreCount: 13 deviceMemorySize: 3.94GiB deviceMemoryBandwidth: 208.91GiB/s\n",
                        "2021-08-26 09:03:42.744374: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/devel/lib:/opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu\n",
                        "2021-08-26 09:03:42.744455: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/devel/lib:/opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu\n",
                        "2021-08-26 09:03:42.744534: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/devel/lib:/opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu\n",
                        "2021-08-26 09:03:42.744598: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/devel/lib:/opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu\n",
                        "2021-08-26 09:03:42.744663: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/devel/lib:/opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu\n",
                        "2021-08-26 09:03:42.744725: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/devel/lib:/opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu\n",
                        "2021-08-26 09:03:42.744787: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/devel/lib:/opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu\n",
                        "2021-08-26 09:03:42.744864: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/devel/lib:/opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu\n",
                        "2021-08-26 09:03:42.744873: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
                        "Skipping registering GPU devices...\n",
                        "2021-08-26 09:03:42.745448: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
                        "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
                        "2021-08-26 09:03:42.745684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
                        "2021-08-26 09:03:42.745694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "source": [
                "observation_spec, action_spec, time_step_spec = (\n",
                "      spec_utils.get_tensor_specs(collect_env))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "source": [
                "with strategy.scope():\n",
                "  critic_net = critic_network.CriticNetwork(\n",
                "        (observation_spec, action_spec),\n",
                "        observation_fc_layer_params=None,\n",
                "        action_fc_layer_params=None,\n",
                "        joint_fc_layer_params=critic_joint_fc_layer_params,\n",
                "        kernel_initializer='glorot_uniform',\n",
                "        last_kernel_initializer='glorot_uniform')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "source": [
                "with strategy.scope():\n",
                "  actor_net = actor_distribution_network.ActorDistributionNetwork(\n",
                "      observation_spec,\n",
                "      action_spec,\n",
                "      fc_layer_params=actor_fc_layer_params,\n",
                "      continuous_projection_net=(\n",
                "          tanh_normal_projection_network.TanhNormalProjectionNetwork))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "source": [
                "with strategy.scope():\n",
                "  train_step = train_utils.create_train_step()\n",
                "\n",
                "  tf_agent = sac_agent.SacAgent(\n",
                "        time_step_spec,\n",
                "        action_spec,\n",
                "        actor_network=actor_net,\n",
                "        critic_network=critic_net,\n",
                "        actor_optimizer=tf.compat.v1.train.AdamOptimizer(\n",
                "            learning_rate=actor_learning_rate),\n",
                "        critic_optimizer=tf.compat.v1.train.AdamOptimizer(\n",
                "            learning_rate=critic_learning_rate),\n",
                "        alpha_optimizer=tf.compat.v1.train.AdamOptimizer(\n",
                "            learning_rate=alpha_learning_rate),\n",
                "        target_update_tau=target_update_tau,\n",
                "        target_update_period=target_update_period,\n",
                "        td_errors_loss_fn=tf.math.squared_difference,\n",
                "        gamma=gamma,\n",
                "        reward_scale_factor=reward_scale_factor,\n",
                "        train_step_counter=train_step)\n",
                "\n",
                "  tf_agent.initialize()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "source": [
                "rate_limiter=reverb.rate_limiters.SampleToInsertRatio(samples_per_insert=3.0, min_size_to_sample=3, error_buffer=3.0)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "source": [
                "table_name = 'uniform_table'\n",
                "table = reverb.Table(\n",
                "    table_name,\n",
                "    max_size=replay_buffer_capacity,\n",
                "    sampler=reverb.selectors.Uniform(),\n",
                "    remover=reverb.selectors.Fifo(),\n",
                "    rate_limiter=reverb.rate_limiters.MinSize(1))\n",
                "\n",
                "reverb_server = reverb.Server([table])"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "[reverb/cc/platform/tfrecord_checkpointer.cc:150]  Initializing TFRecordCheckpointer in /tmp/tmpfkw4mpjz.\n",
                        "[reverb/cc/platform/tfrecord_checkpointer.cc:378] Loading latest checkpoint from /tmp/tmpfkw4mpjz\n",
                        "[reverb/cc/platform/default/server.cc:54] Started replay server on port 18924\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "source": [
                "reverb_replay = reverb_replay_buffer.ReverbReplayBuffer(\n",
                "    tf_agent.collect_data_spec,\n",
                "    sequence_length=2,\n",
                "    table_name=table_name,\n",
                "    local_server=reverb_server)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "source": [
                "dataset = reverb_replay.as_dataset(\n",
                "      sample_batch_size=batch_size, num_steps=2).prefetch(50)\n",
                "experience_dataset_fn = lambda: dataset"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "source": [
                "tf_eval_policy = tf_agent.policy\n",
                "eval_policy = py_tf_eager_policy.PyTFEagerPolicy(\n",
                "  tf_eval_policy, use_tf_function=True)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "source": [
                "tf_collect_policy = tf_agent.collect_policy\n",
                "collect_policy = py_tf_eager_policy.PyTFEagerPolicy(\n",
                "  tf_collect_policy, use_tf_function=True)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "source": [
                "random_policy = random_py_policy.RandomPyPolicy(\n",
                "  collect_env.time_step_spec(), collect_env.action_spec())"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "source": [
                "rb_observer = reverb_utils.ReverbAddTrajectoryObserver(\n",
                "  reverb_replay.py_client,\n",
                "  table_name,\n",
                "  sequence_length=2,\n",
                "  stride_length=1)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "source": [
                "initial_collect_actor = actor.Actor(\n",
                "  collect_env,\n",
                "  random_policy,\n",
                "  train_step,\n",
                "  steps_per_run=initial_collect_steps,\n",
                "  observers=[rb_observer])\n",
                "initial_collect_actor.run()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "source": [
                "env_step_metric = py_metrics.EnvironmentSteps()\n",
                "collect_actor = actor.Actor(\n",
                "  collect_env,\n",
                "  collect_policy,\n",
                "  train_step,\n",
                "  steps_per_run=1,\n",
                "  metrics=actor.collect_metrics(10),\n",
                "  summary_dir=os.path.join(tempdir, learner.TRAIN_DIR),\n",
                "  observers=[rb_observer, env_step_metric])"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "source": [
                "eval_actor = actor.Actor(\n",
                "  eval_env,\n",
                "  eval_policy,\n",
                "  train_step,\n",
                "  episodes_per_run=num_eval_episodes,\n",
                "  metrics=actor.eval_metrics(num_eval_episodes),\n",
                "  summary_dir=os.path.join(tempdir, 'eval'),\n",
                ")"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "source": [
                "saved_model_dir = os.path.join(tempdir, learner.POLICY_SAVED_MODEL_DIR)\n",
                "\n",
                "# Triggers to save the agent's policy checkpoints.\n",
                "learning_triggers = [\n",
                "    triggers.PolicySavedModelTrigger(\n",
                "        saved_model_dir,\n",
                "        tf_agent,\n",
                "        train_step,\n",
                "        interval=policy_save_interval),\n",
                "    triggers.StepPerSecondLogTrigger(train_step, interval=1000),\n",
                "]\n",
                "agent_learner = learner.Learner(\n",
                "  tempdir,\n",
                "  train_step,\n",
                "  tf_agent,\n",
                "  experience_dataset_fn,\n",
                "  triggers=learning_triggers)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "WARNING:tensorflow:From /home/nils/.local/lib/python3.8/site-packages/tensorflow_probability/python/distributions/distribution.py:298: calling MultivariateNormalDiag.__init__ (from tensorflow_probability.python.distributions.mvn_diag) with scale_identity_multiplier is deprecated and will be removed after 2020-01-01.\n",
                        "Instructions for updating:\n",
                        "`scale_identity_multiplier` is deprecated; please combine it with `scale_diag` directly instead.\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "2021-08-26 09:03:47.006140: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "WARNING:tensorflow:From /home/nils/.local/lib/python3.8/site-packages/tf_agents/train/learner.py:145: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
                        "Instructions for updating:\n",
                        "rename to distribute_datasets_from_function\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "2021-08-26 09:03:47.977917: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
                        "2021-08-26 09:03:47.998423: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3192660000 Hz\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "source": [
                "\n",
                "def get_eval_metrics():\n",
                "  print(\"Starte evaluierung\")\n",
                "  eval_actor.run()\n",
                "  results = {}\n",
                "  for metric in eval_actor.metrics:\n",
                "    results[metric.name] = metric.result()\n",
                "  print(\"Evaluierung beendete\")\n",
                "  return results\n",
                "\n",
                "metrics = get_eval_metrics()"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Starte evaluierung\n",
                        "Evaluierung beendete\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "source": [
                "# def get_eval_metrics_collect():\n",
                "#   print(\"Starte evaluierung\")\n",
                "#   collect_actor.run()\n",
                "#   results = {}\n",
                "#   for metric in collect_actor.metrics:\n",
                "#     results[metric.name] = metric.result()\n",
                "#   print(\"Evaluierung beendete\")\n",
                "#   return results\n",
                "\n",
                "# metrics_collect = get_eval_metrics_collect()"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Starte evaluierung\n",
                        "Evaluierung beendete\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "source": [
                "def log_eval_metrics(step, metrics):\n",
                "  eval_results = (', ').join(\n",
                "      '{} = {:.6f}'.format(name, result) for name, result in metrics.items())\n",
                "  print('step = {0}: {1}'.format(step, eval_results))\n",
                "\n",
                "log_eval_metrics(0, metrics)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "step = 0: AverageReturn = -6.510911, AverageEpisodeLength = 1.000000\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "source": [
                "# log_eval_metrics(0, metrics_collect)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "step = 0: NumberOfEpisodes = 1.000000, EnvironmentSteps = 1.000000, AverageReturn = -4.820488, AverageEpisodeLength = 1.000000\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "source": [
                "try:\n",
                "  %%time\n",
                "except:\n",
                "  pass\n",
                "\n",
                "\n",
                "# Reset the train step\n",
                "tf_agent.train_step_counter.assign(0)\n",
                "\n",
                "# Evaluate the agent's policy once before training.\n",
                "avg_return = get_eval_metrics()[\"AverageReturn\"]\n",
                "returns = [avg_return]\n",
                "avg_distance = get_eval_metrics()[\"AverageEpisodeLength\"]\n",
                "distance = [avg_distance]\n",
                "\n",
                "i =0\n",
                "for _ in range(num_iterations):\n",
                "  # Training.\n",
                "  i +=1\n",
                "  collect_actor.run()\n",
                "  loss_info = agent_learner.run(iterations=1)\n",
                "  \n",
                "  # Evaluating.\n",
                "  step = agent_learner.train_step_numpy\n",
                "  if eval_interval and step % eval_interval == 0:\n",
                "    metrics = get_eval_metrics()\n",
                "    log_eval_metrics(step, metrics)\n",
                "    returns.append(metrics[\"AverageReturn\"])\n",
                "    distance.append(metrics[\"AverageEpisodeLength\"])\n",
                "    \n",
                "\n",
                "  if log_interval and step % log_interval == 0:\n",
                "    print('step = {0}: loss = {1}'.format(step, loss_info.loss.numpy()))\n",
                "rb_observer.close()\n",
                "reverb_server.stop()\n",
                "\n"
            ],
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "SyntaxError",
                    "evalue": "invalid syntax (4077647524.py, line 15)",
                    "traceback": [
                        "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_916019/4077647524.py\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    avg_episodeLength = get_eval_metrics_collect()[]\u001b[0m\n\u001b[0m                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "steps = range(0,num_iterations+ 1, eval_interval)\n",
                "returnscrop = returns[:151]\n",
                "plt.plot(steps, returns)\n",
                "plt.ylabel('Average Return')\n",
                "plt.xlabel('Step')\n",
                "plt.ylim()\n",
                "returns"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "plt.plot(steps,distance)\n",
                "plt.ylabel('Distance from Goal')\n",
                "plt.xlabel('Step')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "plt.scatter(steps,returnscrop)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "metrics"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# checkpoint=common.Checkpointer(\n",
                "#      saved_model_dir, max_to_keep=20\n",
                "# )\n",
                "\n",
                "   "
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# checkpoint.initialize_or_restore()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# collect_actor.run()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# try:\n",
                "#   %%time\n",
                "# except:\n",
                "#   pass\n",
                "\n",
                "\n",
                "# # Reset the train step\n",
                "# tf_agent.train_step_counter.assign(0)\n",
                "\n",
                "# # Evaluate the agent's policy once before training.\n",
                "# avg_return = get_eval_metrics()[\"AverageReturn\"]\n",
                "# returns = [avg_return]\n",
                "# i =0\n",
                "# for _ in range(num_iterations):load\n",
                "#   # Training.\n",
                "#   i +=1\n",
                "#   collect_actor.run()\n",
                "#   loss_info = agent_learner.run(iterations=1)\n",
                "  \n",
                "#   # Evaluating.\n",
                "#   step = agent_learner.train_step_numpy\n",
                "#   if eval_interval and step % eval_interval == 0:\n",
                "#     metrics = get_eval_metrics()\n",
                "#     log_eval_metrics(step, metrics)\n",
                "#     returns.append(metrics[\"AverageReturn\"])\n",
                "\n",
                "#   if log_interval and step % log_interval == 0:\n",
                "#     print('step = {0}: loss = {1}'.format(step, loss_info.loss.numpy()))\n",
                "# rb_observer.close()\n",
                "# reverb_server.stop()\n"
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        },
        "interpreter": {
            "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.8",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}