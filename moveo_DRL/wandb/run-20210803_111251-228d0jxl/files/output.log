Start Agent init....
Entered InverseKinematics Env
Entered Moveo Env
[ INFO] [1627981977.519510780]: Loading robot model 'moveo_description'...
[ INFO] [1627981977.520834250]: No root/virtual joint specified in SRDF. Assuming fixed joint
###### Setting Group Moveit with 30 seconds wait...
[ INFO] [1627981979.153477776, 1574.418000000]: Ready to take commands for planning group arm.
<class 'moveo_commander.MoveoCommander'>
launch the init function of the Parent Class robot_gazebo_env_goal.RobotGazeboEnv.....
Entered Gazebo Env
False
launch the init function of the Parent Class robot_gazebo_env_goal.RobotGazeboEnv.....END
Entered Moveo Env END
START Actor init
END Actor init....
NUMBER OF WORKERS=CPUs available for this training=1
END Agent init....
Entered InverseKinematics Env
Entered Moveo Env
###### Setting Group Moveit with 30 seconds wait...
[ INFO] [1627981979.818624422, 1575.031000000]: Ready to take commands for planning group arm.
<class 'moveo_commander.MoveoCommander'>
launch the init function of the Parent Class robot_gazebo_env_goal.RobotGazeboEnv.....
Entered Gazebo Env
False
launch the init function of the Parent Class robot_gazebo_env_goal.RobotGazeboEnv.....END
Entered Moveo Env END
action_spec: BoundedTensorSpec(shape=(5,), dtype=tf.float32, name='action', minimum=array(-3.14159, dtype=float32), maximum=array(3.14159, dtype=float32))
time_step_spec.observation: BoundedTensorSpec(shape=(1,), dtype=tf.float32, name='observation', minimum=array(0., dtype=float32), maximum=array(3., dtype=float32))
time_step_spec.step_type: TensorSpec(shape=(), dtype=tf.int32, name='step_type')
time_step_spec.discount: BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32))
time_step_spec.reward: TensorSpec(shape=(), dtype=tf.float32, name='reward')
Entered reset
0.0
0.0
0.0
0.0
0.0
Aktion tf.Tensor([0], shape=(1,), dtype=int32)
Entered step
Unpause sim
Set action
Action:
0
[31m[ERROR] [1627981979.182123, 1574.432000]: NOT Initialising Simulation Physics Parameters
[33m[WARN] [1627981979.200134, 1574.445000]: Start Init ControllersConnection
[33m[WARN] [1627981979.201784, 1574.445000]: END Init ControllersConnection
/home/nils/anaconda3/envs/moveo_training/lib/python3.9/site-packages/gym/logger.py:30: UserWarning: [33mWARN: Box bound precision lowered by casting to float32
  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))
2021-08-03 11:12:59.388892: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-08-03 11:12:59.389140: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-08-03 11:12:59.390022: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
[31m[ERROR] [1627981979.852829, 1575.058000]: NOT Initialising Simulation Physics Parameters
[33m[WARN] [1627981979.873573, 1575.077000]: Start Init ControllersConnection
[33m[WARN] [1627981979.875948, 1575.077000]: END Init ControllersConnection
Traceback (most recent call last):
  File "/home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/src/moveo_training/scripts/A3C_moveo_ik.py", line 311, in <module>
    main()
  File "/home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/src/moveo_training/scripts/A3C_moveo_ik.py", line 300, in main
    next_time_step = tf_env.step(action)
  File "/home/nils/anaconda3/envs/moveo_training/lib/python3.9/site-packages/tf_agents/environments/tf_environment.py", line 241, in step
    return self._step(action)
  File "/home/nils/anaconda3/envs/moveo_training/lib/python3.9/site-packages/tf_agents/environments/tf_py_environment.py", line 316, in _step
    outputs = tf.numpy_function(
  File "/home/nils/anaconda3/envs/moveo_training/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py", line 201, in wrapper
    return target(*args, **kwargs)
  File "/home/nils/anaconda3/envs/moveo_training/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py", line 686, in numpy_function
    return py_func_common(func, inp, Tout, stateful=True, name=name)
  File "/home/nils/anaconda3/envs/moveo_training/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py", line 573, in py_func_common
    result = func(*[np.array(x) for x in inp])
  File "/home/nils/anaconda3/envs/moveo_training/lib/python3.9/site-packages/tf_agents/environments/tf_py_environment.py", line 303, in _isolated_step_py
    return self._execute(_step_py, *flattened_actions)
  File "/home/nils/anaconda3/envs/moveo_training/lib/python3.9/site-packages/tf_agents/environments/tf_py_environment.py", line 212, in _execute
    return fn(*args, **kwargs)
  File "/home/nils/anaconda3/envs/moveo_training/lib/python3.9/site-packages/tf_agents/environments/tf_py_environment.py", line 299, in _step_py
    self._time_step = self._env.step(packed)
  File "/home/nils/anaconda3/envs/moveo_training/lib/python3.9/site-packages/tf_agents/environments/py_environment.py", line 203, in step
    self._current_time_step = self._step(action)
  File "/home/nils/anaconda3/envs/moveo_training/lib/python3.9/site-packages/tf_agents/environments/batched_py_environment.py", line 166, in _step
    time_steps = self._envs[0].step(actions)
  File "/home/nils/anaconda3/envs/moveo_training/lib/python3.9/site-packages/tf_agents/environments/py_environment.py", line 203, in step
    self._current_time_step = self._step(action)
  File "/home/nils/anaconda3/envs/moveo_training/lib/python3.9/site-packages/tf_agents/environments/wrappers.py", line 117, in _step
    time_step = self._env.step(action)
  File "/home/nils/anaconda3/envs/moveo_training/lib/python3.9/site-packages/tf_agents/environments/py_environment.py", line 203, in step
    self._current_time_step = self._step(action)
  File "/home/nils/anaconda3/envs/moveo_training/lib/python3.9/site-packages/tf_agents/environments/gym_wrapper.py", line 217, in _step
    observation, reward, self._done, self._info = self._gym_env.step(action)
  File "/home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/src/openai_ros/openai_ros/src/openai_ros/robot_gazebo_env_goal.py", line 49, in step
    self._set_action(action)
  File "/home/nils/Documents/Studium/Bachelorarbeit/praktischer_Teil/moveo_DRL/src/moveo_training/scripts/moveo_inverse_kinematic.py", line 138, in _set_action
    self.new_pos = {"Joint_1": action[0],
IndexError: too many indices for array: array is 0-dimensional, but 1 were indexed